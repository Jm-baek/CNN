{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SGD.ipynb","provenance":[],"authorship_tag":"ABX9TyMpF+PY2yLtYo08cRGfi3QL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5h6Lvh38lYTH"},"source":["### GD(Gradient Descent)\n","- 전체 학습 데이터를 기반으로 GD 계산\n","- 입력 데이터가 크고 레이어가 많을 수록 GD를 계산하는데 많은 Computing 자원이 소모\n","\n","### SGD(Stochastic Gradient Descent)\n","- 전체 학습 데이터 중 한 개만 임의로 선택하여 GD 계산\n","- 수렴 정확도가 상대적으로 떨어진다.\n","\n","### Mini - Batch GD\n","- 전체 학습 데이터 중 **특정 크기 만큼**(Batch 크기) 임의로 선택해서 GD 계산\n","\n","\n","일반적으로 Mini - Batch GD가 대부분의 딥러닝 Framework에서 채택됨  \n","전체 학습 데이터 400건으로 할 경우, 랜덤이기 때문에 중복 될 수있다. 따라서 순차적인 Mini-Batch"]},{"cell_type":"markdown","metadata":{"id":"13iPWSPwN_HS"},"source":["# SGD 실습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8w3IFlSyKQu","executionInfo":{"status":"ok","timestamp":1628826365724,"user_tz":-540,"elapsed":380,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"180837ab-5105-4051-ba2e-c4f6a3309881"},"source":["from sklearn.datasets import load_boston\n","import pandas as pd\n","import numpy as np\n","\n","boston = load_boston()\n","print(boston.keys()) \n","# print(boston) # dictionary 타입으로 되어있다."],"execution_count":22,"outputs":[{"output_type":"stream","text":["dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"Ib858T45yLG1","executionInfo":{"status":"ok","timestamp":1628826366025,"user_tz":-540,"elapsed":6,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"bceeff0d-3a2a-4681-fcd7-d5076e9119de"},"source":["bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names)\n","bostonDF['PRICE'] = boston.target     # 종속 변수 추가\n","print(bostonDF.shape)\n","bostonDF.head()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["(506, 14)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>B</th>\n","      <th>LSTAT</th>\n","      <th>PRICE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1.0</td>\n","      <td>296.0</td>\n","      <td>15.3</td>\n","      <td>396.90</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>396.90</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>392.83</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.63</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>396.90</td>\n","      <td>5.33</td>\n","      <td>36.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n","0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n","1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n","2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n","3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n","4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"K-lmwPJWxpZA","executionInfo":{"status":"ok","timestamp":1628826367894,"user_tz":-540,"elapsed":254,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0mJ1dkuoO2y","executionInfo":{"status":"ok","timestamp":1628824769174,"user_tz":-540,"elapsed":303,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["def get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate=0.01):\n","    \n","    # 데이터 건수\n","    N = target_sgd.shape[0]   # 한 개\n","\n","    # 예측 값\n","    predicted_sgd = w1 * rm_sgd + w2  * lstat_sgd + bias   # 506개를 한 꺼번에 계산(column)\n","    \n","    # 실제 값과 예측값의 차이\n","    diff_sgd = target_sgd - predicted_sgd     # 잔차(Residual)\n","    \n","    bias_factor = np.ones((N,))  # 편향(bias)\n","\n","    w1_update = -(2/N) * learning_rate * (np.dot(rm_sgd.T, diff_sgd))      # w1를 기준으로 편미분\n","    w2_update = -(2/N) * learning_rate * (np.dot(lstat_sgd.T, diff_sgd))   # w1를 기준으로 편미분\n","    bias_update = -(2/N) * learning_rate * (np.dot(bias_factor.T, diff_sgd))\n","\n","    return bias_update, w1_update, w2_update"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RNKLon68qxMI","executionInfo":{"status":"ok","timestamp":1628824751355,"user_tz":-540,"elapsed":361,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["# RM, LSTAT feature array와 PRICE target array를 입력 받아서 iter_epochs 수만큼 반복적으로 Weight와 Bias를 update 적용.\n","def st_gradient_descent(features, target, iter_epochs=1000, verbose=True):\n","    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n","    # bias도 1차원 array로 변환하되 초기 값은 1로 설정.\n","    w1 = np.zeros((1,))    # 원래는 랜덤 값으로 하는게 맞다.\n","    w2 = np.zeros((1,))\n","    bias = np.ones((1,))\n","    print('최초 w1, w2, bias:', w1, w2, bias)\n","\n","    # learning_rate와 RM, LSTAT 피처 저장,호출 시 numpy array 형태로 RM과 LSTAT로 된 2차원 feature가 입력됨.\n","    learning_rate = 0.01\n","    rm = features[:, 0]\n","    lstat = features[:, 1]\n","\n","    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행\n","    for i in range(iter_epochs):\n","        # iteration 마다 stochapstic gradient descent 를 수행할 데이터를 한 개만 추출. 추출할 데이터의 인덱스를 random.choice() 로 선택.\n","        stochastic_index = np.random.choice(target.shape[0], 1)\n","        rm_sgd = rm[stochastic_index]\n","        lstat_sgd = lstat[stochastic_index]\n","        target_sgd = target[stochastic_index]\n","\n","        # SGD 기반으로 weight/bias update 값 계산\n","        bias_update, w1_update, w2_update = get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate)\n","        # SGD로 구한 weight/bias의 update 적용\n","        w1 = w1 - w1_update\n","        w2 = w2 - w2_update\n","        bias = bias - bias_update\n","        if verbose:\n","            print(\"Epoch: \", i + 1, \"/\", iter_epochs)\n","            # Loss는 전체 학습 데이터 기반으로 구해야 한다.\n","            predicted = w1 * rm + w2 * lstat + bias\n","            diff = target - predicted\n","            mse_loss = np.mean(np.square(diff))\n","            print(\"w1:\", w1, \"w2:\", w2, \"bias:\", bias, \"loss\", mse_loss)\n","\n","    return w1, w2, bias"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KU-yaoHyFjc"},"source":["w1, w2, bias = st_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=1000, verbose=True)\n","print(\" #### 최종 w1, w2, bias #### \")\n","print(w1, w2, bias)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EPW7W6YQOBuy"},"source":["# Mini - Batch 실습\n","- batch size 만큼 데이터가 학습 한다."]},{"cell_type":"code","metadata":{"id":"ECPMz-e3OH77","executionInfo":{"status":"ok","timestamp":1628825851921,"user_tz":-540,"elapsed":252,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["def get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate=0.01):\n","    \n","    # 데이터 건수\n","    N = target_batch.shape[0]\n","    # 예측 값. \n","    predicted_batch = w1 * rm_batch+ w2 * lstat_batch + bias\n","    # 실제값과 예측값의 차이 \n","    diff_batch = target_batch - predicted_batch\n","    # bias 를 array 기반으로 구하기 위해서 설정. \n","    bias_factors = np.ones((N,))\n","    \n","    # weight와 bias를 얼마나 update할 것인지를 계산.  \n","    w1_update = -(2/N)*learning_rate*(np.dot(rm_batch.T, diff_batch))\n","    w2_update = -(2/N)*learning_rate*(np.dot(lstat_batch.T, diff_batch))\n","    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_batch))\n","    \n","    # Mean Squared Error값을 계산. \n","    #mse_loss = np.mean(np.square(diff))\n","    \n","    # weight와 bias가 update되어야 할 값 반환 \n","    return bias_update, w1_update, w2_update"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ohhkFYzjOzNy","executionInfo":{"status":"ok","timestamp":1628825990282,"user_tz":-540,"elapsed":380,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음.\n","def batch_gradient_descent(features, target, iter_epochs=1000, batch_size = 30, verbose=True):\n","    np.random.seed = 2001\n","    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n","    # bias도 1차원 array로 변환하되 초기 값은 1로 설정.\n","    w1 = np.zeros((1,))    # 원래는 랜덤 값으로 하는게 맞다.\n","    w2 = np.zeros((1,))\n","    bias = np.ones((1,))\n","    print('최초 w1, w2, bias:', w1, w2, bias)\n","\n","    # learning_rate와 RM, LSTAT 피처 저장,호출 시 numpy array 형태로 RM과 LSTAT로 된 2차원 feature가 입력됨.\n","    learning_rate = 0.01\n","    rm = features[:, 0]\n","    lstat = features[:, 1]\n","\n","    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행\n","    for i in range(iter_epochs):\n","        print(f\"현재 iteration은 {i}입니다.\")\n","        # batch_size 만큼 데이터를 가져와서 weight/bias update를 수행하는 로직을 전체 데이터 건수만큼 반복\n","        for batch_step in range(0, target.shape[0], batch_size): # 0 ~ 506 을 batch_size만큼 나눠서 출력\n","            # batch_szie만큼 순차적인 데이터를 가져옴.\n","            # 0 ~ 30, 30 ~ 60, 60 ~ 90 ...\n","            rm_batch = rm[batch_step:batch_step + batch_size]\n","            lstat_batch = lstat[batch_step:batch_step + batch_size]\n","            target_batch = target[batch_step:batch_step + batch_size]\n","\n","            # SGD 기반으로 weight/bias update 값 계산\n","            bias_update, w1_update, w2_update = get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n","            # SGD로 구한 weight/bias의 update 적용\n","            w1 = w1 - w1_update\n","            w2 = w2 - w2_update\n","            bias = bias - bias_update\n","            if verbose:\n","                print(\"Epoch :\", i + 1, \"/\", iter_epochs, 'batch step:', batch_step)\n","                # Loss는 전체 학습 데이터 기반으로 구해야 한다.\n","                predicted = w1 * rm + w2 * lstat + bias\n","                diff = target - predicted\n","                mse_loss = np.mean(np.square(diff))\n","                print(\"w1:\", w1, \"w2:\", w2, \"bias:\", bias, \"loss\", mse_loss)\n","\n","    return w1, w2, bias"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXIxjpV2e2sG"},"source":["w1, w2, bias = batch_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs = 5000, batch_size=30, verbose=True)\n","print(\"##### 최종 w1, w2, bias ######\")\n","print(w1, w2, bias)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-NzmPviZTSo"},"source":["### 참고 예시"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Q5S_UxLSEAz","executionInfo":{"status":"ok","timestamp":1628820851984,"user_tz":-540,"elapsed":263,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"33e01fae-51c4-46d2-d78b-40dea26c7d8f"},"source":["batch_indexes = np.random.choice(506, 30)\n","print(batch_indexes)\n","\n","# random하게 뽑은 인덱스로 RM값 추출\n","bostonDF['RM'].values[batch_indexes]"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[382  83 482 142 269 417  83  44 232 294 259 436 381 224 117 407  94 237\n","  77 343 241   4   8 233 190 370 237 343 283 443]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([5.536, 6.167, 7.061, 5.403, 5.92 , 5.304, 6.167, 6.069, 8.337,\n","       6.009, 6.842, 6.461, 6.545, 8.266, 6.021, 5.608, 6.249, 7.358,\n","       6.14 , 6.696, 6.095, 7.147, 5.631, 8.247, 6.951, 7.016, 7.358,\n","       6.696, 7.923, 6.485])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"fDzYUm7ZZIm6"},"source":["for batch_step in range(0, 506, 30):\n","    print(batch_step)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"zOlgR7YBSJcU","executionInfo":{"status":"error","timestamp":1628824009010,"user_tz":-540,"elapsed":240,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"bbd86ccc-6673-4ea4-a77b-99b6833f419e"},"source":["# 이렇게 되면 오류가 발생한다.\n","bostonDF['PRICE'].values[507]"],"execution_count":7,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-2323c717d87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 이렇게 되면 오류가 발생한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbostonDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PRICE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m507\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: index 507 is out of bounds for axis 0 with size 506"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdkRxx_gefbL","executionInfo":{"status":"ok","timestamp":1628824031589,"user_tz":-540,"elapsed":339,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"1401bf2b-e3b1-4f84-8a56-aa48b1d9c2a6"},"source":["# 최대한 찾을 수 있는 부분까지 찾아준다.\n","bostonDF['PRICE'].values[480:510]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([23. , 23.7, 25. , 21.8, 20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1,\n","       13.6, 20.1, 21.8, 24.5, 23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4,\n","       20.6, 23.9, 22. , 11.9])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"fivSU88jek6i"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pksFUQAgmKa2"},"source":["# keras로 작업하기"]},{"cell_type":"code","metadata":{"id":"6jzDHCyjmLrU"},"source":["from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential([\n","    # 단 하나의 units 설정. input_shape는 2차원, 회귀이므로 activation은 설정하지 않음. \n","    # weight와 bias 초기화는 kernel_inbitializer와 bias_initializer를 이용. \n","    Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n","])\n","# Adam optimizer를 이용하고 Loss 함수는 Mean Squared Error, 성능 측정 역시 MSE를 이용하여 학습 수행. \n","model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n","\n","# Keras는 반드시 Batch GD를 적용함. batch_size가 None이면 32를 할당. \n","model.fit(scaled_features, bostonDF['PRICE'].values, batch_size=30, epochs=1000)"],"execution_count":null,"outputs":[]}]}