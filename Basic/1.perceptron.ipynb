{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1.perceptron.ipynb","provenance":[],"authorship_tag":"ABX9TyMH8puppvJaC5Zlc2XGouTL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kuE-CBFeKPu","executionInfo":{"status":"ok","timestamp":1628573413542,"user_tz":-540,"elapsed":6,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"2884ef3f-0083-43a1-d8cc-a8d1440d040b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bo8icUszgrTj"},"source":["![이미지 출력 필요](/content/drive/MyDrive/Study/Images/1.perceptron.png)"]},{"cell_type":"markdown","metadata":{"id":"7jhcAHKKplez"},"source":["### 퍼셉트론의 학습\n","\n","출력 = $F(w_0 + w_1 *x_1 + w_2 * x_2 + ... + w_n *x_n)$  = Weighted Sum  \n","$w_o$은 bias이다.\n","입력(x) * 가중치(w) + 편향(bias)   \n","\n","#### 1.퍼셉트론 특징\n","1. 퍼셉트론은 hidden layer가 존재하지 않는다.\n","2. single layer로 구성되어있다.\n"," - input, weight, activation, output\n","\n","#### 2.Activation function 이란?\n","1. 임계점(threshold)이 넘어가면 1, 안 넘어가면 0 이다.\n","2. 비선형으로 변형할 수 있다.\n","\n","\n","\n","#### 3.How 예측값과 실제 값의 차이를 줄는지?\n","- 경사하강법(Gradient descent)을 사용\n","   \n","\n"]},{"cell_type":"markdown","metadata":{"id":"OlPrJcsXobVv"},"source":["### 회귀(Regression) 개요\n","목표: 최적의 회귀 계수를 찾아낸다.  \n","\n","$ Y = w_1 * x_1 + w_2 * x_2 + ... w_n * x_n$\n","\n","1. x는 독립변수(feature), y는 종속변수\n","2. w는 회귀 계수(regression coefficients)\n","\n","선형회귀는 완벽하게 정답에 대해 일직선 선을 그을 수 없다.  \n","실제 값과 예측 값의 차이(잔차)를 최소로 만드는 최적의 회귀 계수를 찾아야한다.  \n","\n","### 오류 측정 방법\n","1. RSS(Residual Sum of Square)\n","    - 잔차 제곱의 합\n","    - 잔차를 다 더하면 0 이 나온다.\n","    - w 변수(회귀 계수)가 중심 변수임을 인지하는 것이 매우 중요한다.\n","\n","2. MSE(Mean Squared Error)\n","    - RSS에서 학습 개수로 나눈 값이다.\n","    - MSE 는 비용(Cost)이며 w(회귀 계수)로 구성되는 MSE를 비용 함수라고 한다.\n","    - 머신 러닝 회귀 알고리즘은 데이터를 계속 학습하면서 비용 함수가 반환하는 값(오류값)을 계속해서 감소시키고 최종적으로 더 이상 감소하지 않는 최소의 오류 값을 구하는 것이다.\n","    - 비용 함수를 손실함수(loss fucntion)이라고 한다.\n","\n","### 경사하강법\n","1. 어떻게 하면 오류가 작아지는 방향으로 W 값을 보정할 수 있을까? \n","2. 미분은 증가 또는 감소의 방향성을 나타낸다.\n","3. Loss(w)를 편미분해 미분 함수의 최솟값을 구해야하는데, Loss(w)는 두 개의 파라미터인 $w_0$과 $w_1$을 각각 가지고 잇기 떄문에 편미분을 적용해야한다.\n","4. 가중치/절편 W 값은 손실 함수의 편미분 값을 Update 하면서 계속 갱신함.\n","5. Update는 기존 W 값에 손실 함수 편미분 값을 감소 시키는 방식을 정용하되 편미분 값을 그냥 감소 시키지 않고 일정한 계수를 곱해서 감소 시키며, 이를 학습률(learning rate)라고 한다.\n","6. 학습률이 큰 경우, 빠르게 학습이 가능 하지만 최소값을 지나칠 수 있다. 학습률이 작은 경우, 학습 속도가 오래 걸릴 수 있다.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"uPSiM0qboCSN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628774697727,"user_tz":-540,"elapsed":1173,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"d56da18b-5d6e-4d2d-e50b-0d1c35e8d48f"},"source":["from sklearn.datasets import load_boston\n","import pandas as pd\n","import numpy as np\n","\n","boston = load_boston()\n","print(boston.keys()) \n","# print(boston) # dictionary 타입으로 되어있다."],"execution_count":1,"outputs":[{"output_type":"stream","text":["dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h1rwBJAUiMGG","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"ok","timestamp":1628774698024,"user_tz":-540,"elapsed":12,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"25ac7b65-6758-4fda-e80c-b985ecc9cf33"},"source":["bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names)\n","bostonDF['PRICE'] = boston.target     # 종속 변수 추가\n","print(bostonDF.shape)\n","bostonDF.head()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(506, 14)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>B</th>\n","      <th>LSTAT</th>\n","      <th>PRICE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1.0</td>\n","      <td>296.0</td>\n","      <td>15.3</td>\n","      <td>396.90</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>396.90</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>392.83</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.63</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>396.90</td>\n","      <td>5.33</td>\n","      <td>36.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  PRICE\n","0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98   24.0\n","1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14   21.6\n","2  0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03   34.7\n","3  0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94   33.4\n","4  0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33   36.2\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"eGcRnLUz485D","executionInfo":{"status":"ok","timestamp":1628774698025,"user_tz":-540,"elapsed":7,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["# rm은 RM(방개수), lstat(하위계층 비율), target은 PRICE\n","# 반환 값은 weight와 bias가 update되어야 할 값과 Meas Squared Error 값을 loss로 반환.\n","def get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate):\n","    \n","    N = len(target)\n","\n","    predicted = w1 * rm + w2  * lstat + bias   # 506개를 한 꺼번에 계산(column)\n","    diff = target - predicted     # 잔차(Residual)\n","    bias_factor = np.ones((N,))  # 편향(bias)\n","\n","    w1_update = -(2/N) * learning_rate * (np.dot(rm.T, diff))      # w1를 기준으로 편미분\n","    w2_update = -(2/N) * learning_rate * (np.dot(lstat.T, diff))   # w1를 기준으로 편미분\n","    bias_update = -(2/N) * learning_rate * (np.dot(bias_factor.T, diff))\n","\n","    mse_loss = np.mean(np.square(diff))\n","\n","    return bias_update, w1_update, w2_update, mse_loss"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9OTpZ3B-bID","executionInfo":{"status":"ok","timestamp":1628774698902,"user_tz":-540,"elapsed":3,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["# RM, LSTAT feature array와 PRICE target array를 입력 받아서 iter_epochs 수만큼 반복적으로 Weight와 Bias를 update 적용.\n","def gradient_descent(features, target, iter_epochs=1000, verbose=True):\n","    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n","    # bias도 1차원 array로 변환하되 초기 값은 1로 설정.\n","    w1 = np.zeros((1,))    # 원래는 랜덤 값으로 하는게 맞다.\n","    w2 = np.zeros((1,))\n","    bias = np.ones((1,))\n","    print('최초 w1, w2, bias:', w1, w2, bias)\n","\n","    # learning_rate와 RM, LSTAT 피처 저장,호출 시 numpy array 형태로 RM과 LSTAT로 된 2차원 feature가 입력됨.\n","    learning_rate = 0.01\n","    rm = features[:, 0]\n","    lstat = features[:, 1]\n","\n","    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행\n","    for i in range(iter_epochs):\n","        # weight/bias update 값 계산\n","        bias_update, w1_update, w2_update, loss = get_update_weights_value(bias, w1, w2, rm, lstat, target, learning_rate)\n","        # weight/bias의 update 적용\n","        w1 = w1 - w1_update\n","        w2 = w2 - w2_update\n","        bias = bias - bias_update\n","        if verbose:\n","            print(\"Epoch: \", i + 1, \"/\", iter_epochs)\n","            print(\"w1:\", w1, \"w2:\", w2, \"bias:\", bias, \"loss\", loss)\n","\n","    return w1, w2, bias"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bq4-8itnCgoV"},"source":["## Gradient descent 적용\n","    - 정규화/표준화 작업을 미리 선행\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcbOVr0OLGEt","executionInfo":{"status":"ok","timestamp":1628774700812,"user_tz":-540,"elapsed":4,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"66b9e76c-121c-4b0e-fdd3-7ef838b5f4b6"},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n","print(scaled_features[:15])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[[0.57750527 0.08967991]\n"," [0.5479977  0.2044702 ]\n"," [0.6943859  0.06346578]\n"," [0.65855528 0.03338852]\n"," [0.68710481 0.09933775]\n"," [0.54972217 0.09602649]\n"," [0.4696302  0.29525386]\n"," [0.50028741 0.48068433]\n"," [0.39662771 0.7781457 ]\n"," [0.46809734 0.424117  ]\n"," [0.53956697 0.51655629]\n"," [0.46905537 0.31843267]\n"," [0.44606246 0.38576159]\n"," [0.45755892 0.18018764]\n"," [0.48572523 0.23537528]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HTL0SaTLBKpL"},"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","sclaer = MinMaxScaler()\n","scaled_feature = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n","\n","# scaled_feature 값을 넣는다.\n","# .value 는 array로 바꿔준다.\n","w1, w2, bias = gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=1000, verbose=True )\n","print(\" ### 최종 w1, w2, bias #####\")\n","print(w1, w2, bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98iS6pvrLgxq","executionInfo":{"status":"ok","timestamp":1628775066829,"user_tz":-540,"elapsed":520,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}}},"source":["from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential([\n","    Dense(1, input_shape=(2,), activation = None, kernel_initializer='zeros', bias_initializer='ones')       \n","])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWpah1fli4gN"},"source":["model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n","model.fit( x= scaled_features, y= bostonDF['PRICE'].values, epochs=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"KRV7Tf9TkJGk","executionInfo":{"status":"ok","timestamp":1628775277589,"user_tz":-540,"elapsed":257,"user":{"displayName":"JongMin Baek","photoUrl":"","userId":"06042548899404878514"}},"outputId":"12e3db30-d745-4a67-9299-662b25073665"},"source":["predicted = model.predict(scaled_features)\n","bostonDF['predicted_price'] = predicted\n","bostonDF.head(10)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>B</th>\n","      <th>LSTAT</th>\n","      <th>PRICE</th>\n","      <th>predicted_price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0.0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1.0</td>\n","      <td>296.0</td>\n","      <td>15.3</td>\n","      <td>396.90</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","      <td>28.968979</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>396.90</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","      <td>25.495987</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0.0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2.0</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>392.83</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","      <td>32.624313</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.63</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","      <td>32.402267</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>396.90</td>\n","      <td>5.33</td>\n","      <td>36.2</td>\n","      <td>31.589417</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.02985</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0.0</td>\n","      <td>0.458</td>\n","      <td>6.430</td>\n","      <td>58.7</td>\n","      <td>6.0622</td>\n","      <td>3.0</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.12</td>\n","      <td>5.21</td>\n","      <td>28.7</td>\n","      <td>28.097370</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.08829</td>\n","      <td>12.5</td>\n","      <td>7.87</td>\n","      <td>0.0</td>\n","      <td>0.524</td>\n","      <td>6.012</td>\n","      <td>66.6</td>\n","      <td>5.5605</td>\n","      <td>5.0</td>\n","      <td>311.0</td>\n","      <td>15.2</td>\n","      <td>395.60</td>\n","      <td>12.43</td>\n","      <td>22.9</td>\n","      <td>21.319248</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.14455</td>\n","      <td>12.5</td>\n","      <td>7.87</td>\n","      <td>0.0</td>\n","      <td>0.524</td>\n","      <td>6.172</td>\n","      <td>96.1</td>\n","      <td>5.9505</td>\n","      <td>5.0</td>\n","      <td>311.0</td>\n","      <td>15.2</td>\n","      <td>396.90</td>\n","      <td>19.15</td>\n","      <td>27.1</td>\n","      <td>17.744389</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.21124</td>\n","      <td>12.5</td>\n","      <td>7.87</td>\n","      <td>0.0</td>\n","      <td>0.524</td>\n","      <td>5.631</td>\n","      <td>100.0</td>\n","      <td>6.0821</td>\n","      <td>5.0</td>\n","      <td>311.0</td>\n","      <td>15.2</td>\n","      <td>386.63</td>\n","      <td>29.93</td>\n","      <td>16.5</td>\n","      <td>8.037947</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.17004</td>\n","      <td>12.5</td>\n","      <td>7.87</td>\n","      <td>0.0</td>\n","      <td>0.524</td>\n","      <td>6.004</td>\n","      <td>85.9</td>\n","      <td>6.5921</td>\n","      <td>5.0</td>\n","      <td>311.0</td>\n","      <td>15.2</td>\n","      <td>386.71</td>\n","      <td>17.10</td>\n","      <td>18.9</td>\n","      <td>18.241455</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      CRIM    ZN  INDUS  CHAS  ...       B  LSTAT  PRICE  predicted_price\n","0  0.00632  18.0   2.31   0.0  ...  396.90   4.98   24.0        28.968979\n","1  0.02731   0.0   7.07   0.0  ...  396.90   9.14   21.6        25.495987\n","2  0.02729   0.0   7.07   0.0  ...  392.83   4.03   34.7        32.624313\n","3  0.03237   0.0   2.18   0.0  ...  394.63   2.94   33.4        32.402267\n","4  0.06905   0.0   2.18   0.0  ...  396.90   5.33   36.2        31.589417\n","5  0.02985   0.0   2.18   0.0  ...  394.12   5.21   28.7        28.097370\n","6  0.08829  12.5   7.87   0.0  ...  395.60  12.43   22.9        21.319248\n","7  0.14455  12.5   7.87   0.0  ...  396.90  19.15   27.1        17.744389\n","8  0.21124  12.5   7.87   0.0  ...  386.63  29.93   16.5         8.037947\n","9  0.17004  12.5   7.87   0.0  ...  386.71  17.10   18.9        18.241455\n","\n","[10 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"2yhTKYw6kmGk"},"source":[""],"execution_count":null,"outputs":[]}]}